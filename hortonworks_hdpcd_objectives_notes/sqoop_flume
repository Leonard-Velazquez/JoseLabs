My SQL Server install in centos

 install the server - sudo yum install mysql-server
 start the service - sudo /sbin/service mysqld start
 secure installation - sudo /usr/bin/mysql_secure_installation
 
 start the mysql 
mysql -uroot -pcloudera (root user)
 
http://hortonworks.com/training/certification/exam-objectives/#hdpcd

1. Import data from a table in a relational database into HDFS

to show all the database names at present ==> show database;
to select a database ==> use database_name;
to show tables in that database ==> show tables;

Data in HDFS
sqoop import --connect jdbc:mysql://localhost:3306/retail_db --username root --password cloudera --query 'select * from customers where $CONDITIONS' --split-by customers.customer_id  --target-dir /home/cloudera/jthiyaga/sqooptest
QueryResult.java files gets created and hdfs data can be seen in this path "/home/cloudera/jthiyaga/sqooptest"

Data in Hive
 command ==> sqoop import --connect jdbc:mysql://localhost:3306/retail_db --username root --password cloudera --table products --hive-import --hive-table productimport --target-dir /home/cloudera/jthiyaga/sqooptest/
 For the above query 4 mappers are being used. The output can be checked in hdfs dir. hdfs dfs -ls /home/cloudera/jthiyaga/sqoopcheck
 
 Just go to this path "/home/cloudera/jthiyaga/sqooptest/" to check a java file named "products.java"(table name which you have given in sqoop commmand).
 It is a POJO class with equals method, class implements mapred interface like DBWritable and Writable 
 
reference: http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.3.0/bk_dataintegration/content/using_sqoop_to_move_data_into_hive.html


2 Import the results of a query from a relational database into HDFS


reference : http://hadooped.blogspot.in/2013/05/apache-sqoop-for-data-integration.html

3 Import a table from a relational database into a new or existing Hive table
 create a table in hive with the right table definition. Using sqoop import command import the data from RDMS to Hive.
 
4 Insert or update data from HDFS into a table in a relational database

5 Given a Flume configuration file, start a Flume agent
Flume to HDFS
https://www.cloudera.com/documentation/other/tutorial/CDH5/topics/ht_flume_to_hdfs.html

6 Given a configured sink and source, configure a Flume memory channel with a specified capacity
https://www.youtube.com/watch?v=dU-mapwDEC0
